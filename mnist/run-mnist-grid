#!/usr/bin/env python 


from __future__ import division

import sys
sys.path.append("../")

import logging
from time import time
import cPickle as pickle

import numpy as np

from learning.training import Trainer
from learning.termination import EarlyStopping
from learning.monitor import MonitorLL, DLogModelParams, SampleFromP
from learning.dataset import BarsData, FromModel, MNIST
from learning.experiment import Experiment

from learning.isws import ISStack
from learning.sbn  import SBN, SBNTop
from learning.darn import DARN, DARNTop
from learning.nade import NADE, NADETop

TAGS = ['lr33', 'clamp']
SPECS = (
	# name, batch_size, samples, p-layer, q-layer, arch,
	("sbn-sbn-ws-200", 			25, 1 , SBN, SBN, [200]),
	("sbn-sbn-ws-500", 			25, 1 , SBN, SBN, [500]),
	("sbn-sbn-ws-200-200", 		25, 1 , SBN, SBN, [200, 200]),	
	("sbn-sbn-ws-200-200-200",	25, 1 , SBN, SBN, [200, 200, 200]),		

	("sbn-sbn-200", 			25, 5 , SBN, SBN, [200]),
	("sbn-sbn-500", 			25, 5 , SBN, SBN, [500]),
	("sbn-sbn-200-200", 		25, 5 , SBN, SBN, [200, 200]),	
	("sbn-sbn-200-200-200",		25, 5 , SBN, SBN, [200, 200, 200]),		

	("sbn-darn-200", 			25, 5 , SBN, DARN, [200]),
	("sbn-darn-500", 			25, 5 , SBN, DARN, [500]),
	("sbn-darn-200-200", 		25, 5 , SBN, DARN, [200, 200]),	
	("sbn-darn-200-200-200", 	25, 5 , SBN, DARN, [200, 200, 200]),		

	("sbn-nade-200", 			25, 5 , SBN, DARN, [200]),
	("sbn-nade-500", 			25, 5 , SBN, DARN, [500]),
	("sbn-nade-200-200", 		25, 5 , SBN, DARN, [200, 200]),	
	("sbn-nade-200-200-200", 	25, 5 , SBN, DARN, [200, 200, 200]),		

	("darn-darn-200", 			25, 5 , DARN, DARN, [200]),
	("darn-darn-500", 			25, 5 , DARN, DARN, [500]),
	("darn-darn-200-200", 		25, 5 , DARN, DARN, [200, 200]),	
	("darn-darn-200-200-200", 	25, 5 , DARN, DARN, [200, 200, 200]),		

	("darn-nade-200", 			25, 5 , DARN, NADE, [200]),
	("darn-nade-500", 			25, 5 , DARN, NADE, [500]),
	("darn-nade-200-200", 		25, 5 , DARN, NADE, [200, 200]),	
	("darn-nade-200-200-200", 	25, 5 , DARN, NADE, [200, 200, 200]),			

	("nade-nade-200", 			25, 5 , NADE, NADE, [200]),
	("nade-nade-500", 			25, 5 , NADE, NADE, [500]),
	("nade-nade-200-200", 		25, 5 , NADE, NADE, [200, 200]),	
	("nade-nade-200-200-200", 	25, 5 , NADE, NADE, [200, 200, 200]),		
)

_logger = logging.getLogger()


def run_experiment(spec):
    name, batch_size, n_samples, p_layer, q_layer, arch = spec

    _logger.info("Running %s" % name)

    if p_layer == SBN:
        p_top = SBNTop
    elif p_layer == DARN:
        p_top = DARNTop
    elif p_layer == NADE:
        p_top = NADETop
    else:
        raise "Unknown Top"
    
    p_layers = []
    q_layers = []

    n_X = 28*28

    for ls in arch:
        n_Y = ls
        p_layers.append(
            p_layer(n_X=n_X, n_Y=n_Y, clamp_sigmoid=True)
        )
        q_layers.append(
            q_layer(n_X=n_Y, n_Y=n_X)
        )
        n_X = n_Y
    p_layers.append( p_top(n_X=n_X, clamp_sigmoid=True) )
            

    model = ISStack(
        p_layers=p_layers,
        q_layers=q_layers
    )
    model.setup()

    dataset  = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='salakhutdinov_train', n_datapoints=59000)
    valiset  = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='salakhutdinov_valid', n_datapoints=1000)
    testset  = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='test', n_datapoints=10000)

    #valiset  = MNIST(fname="data/mnist_salakhutdinov.pkl.gz", which_set='salakhutdinov_valid', n_datapoints=1000)
    #dataset  = valiset
    #testset  = valiset

    lr=3e-3
    # Switch to wake-sleep when n_samples=1
    if n_samples == 1:
        lr_p = lr
        lr_q = 0.
        lr_s = lr
    else:
        lr_p = lr
        lr_q = lr
        lr_s = lr
    
    trainer = Trainer(
        batch_size=batch_size,
        n_samples=n_samples,
        learning_rate_p=lr_p,
        learning_rate_q=lr_q,
        learning_rate_s=lr_s,
        layer_discount=1.0,
        anneal=1.,
        dataset=dataset, 
        model=model,
        termination=EarlyStopping(lookahead=5),
#        termination=EarlyStopping(max_epochs=1),
        epoch_monitors=[MonitorLL(data=valiset, n_samples=100), DLogModelParams(), SampleFromP(n_samples=100)],
        final_monitors=[MonitorLL(data=testset, n_samples=[1, 5, 10, 25, 100, 500])],
    )

    tagname = "-".join(TAGS)

    experiment = Experiment()
    experiment.trainer = trainer
    experiment.setup_output_dir("%s-%s" % (tagname, name))
    experiment.print_summary()
    experiment.setup_logging()

    meta = {
        "tag"         : tagname,
        "tags"        : TAGS,
        "name"        : name,
        "batch_size"  : batch_size,
        "n_samples"   : n_samples,
        "p_layer"     : p_layer,
        "q_layer"     : q_layer,
        "arch"        : arch,
        "out_dir"     : experiment.out_dir
    }
   
    with open("run-mnist-grid.%s.state"%tagname, "a") as f:
        pickle.dump(meta, f)
    
    experiment.run_experiment()
    logger.info("Finished. Wrinting metadata")

    experiment.print_summary()

#=============================================================================
if __name__ == "__main__":
    import argparse 

    logger = logging.getLogger(__name__)

    parser = argparse.ArgumentParser()
    parser.add_argument('--verbose', '-v', action='count')
    parser.add_argument('--random', "-z", action='store_true')
    parser.add_argument('--slurm', action='store_true')
    parser.add_argument('name', nargs='*')
    args = parser.parse_args()

    FORMAT = '[%(asctime)s] %(module)-15s %(message)s'
    DATEFMT = "%H:%M:%S"
    logging.basicConfig(format=FORMAT, datefmt=DATEFMT, level=logging.INFO)

    if args.random:
        logger.info("Randomly chosing one of %d experiments" % len(SPECS))
        i = np.random.randint(len(SPECS))
        run_experiment(SPECS[i])
    elif args.slurm:
        i = 0
        run_experiment(SPECS[i])
    else:
        for spec in SPECS:
            name, batch_size, n_samples, p_layers, q_layers, arch = spec

            if name in args.name:
                run_experiment(spec)
#        	print "%40s (batch_size=%d, n_samples=%d, arch=%s)" % (name, batch_size, n_samples, arch)


