#!/usr/bin/env python 


from __future__ import division

import sys
sys.path.append("../")

import logging
from time import time
import cPickle as pickle

import numpy as np

from learning.experiment import Experiment
from learning.training import Trainer
from learning.termination import EarlyStopping
from learning.monitor import MonitorLL, DLogModelParams, SampleFromP
from learning.dataset import MNIST
from learning.preproc import PermuteColumns

from learning.isws import ISStack
from learning.sbn  import SBN, SBNTop
from learning.darn import DARN, DARNTop
from learning.nade import NADE, NADETop

TAGS = ['lr13', 'nanguard']
SPECS = (
	# name, batch_size, samples, p-layer, q-layer, arch,
	("ws-sbn-sbn-200", 			25, 1 , SBN, SBN, [200]),
	("ws-sbn-sbn-500", 			25, 1 , SBN, SBN, [500]),
	("ws-sbn-sbn-500", 			25, 1 , SBN, SBN, [500]),
	("ws-sbn-sbn-200-200", 		25, 1 , SBN, SBN, [200, 200]),	
	("ws-sbn-sbn-200-200-10",	25, 1 , SBN, SBN, [200, 200, 10]),		

	("spl02-sbn-sbn-200", 			25,   2 , SBN, SBN, [200]),
	("spl02-sbn-sbn-200-200", 		25,   2 , SBN, SBN, [200, 200]),	
	("spl02-sbn-sbn-200-200-10",    25,   2 , SBN, SBN, [200, 200, 10]),	
	("spl10-sbn-sbn-200", 			25,  10 , SBN, SBN, [200]),
	("spl10-sbn-sbn-200-200", 		25,  10 , SBN, SBN, [200, 200]),	
	("spl10-sbn-sbn-200-200-10",	25,  10 , SBN, SBN, [200, 200, 10]),	
	("spl25-sbn-sbn-200", 			25,  25 , SBN, SBN, [200]),
	("spl25-sbn-sbn-200-200", 		25,  25 , SBN, SBN, [200, 200]),	
	("spl25-sbn-sbn-200-200-10", 	25,  25 , SBN, SBN, [200, 200, 10]),	
	("spl50-sbn-sbn-200", 			25,  50 , SBN, SBN, [200]),
	("spl50-sbn-sbn-200-200-10", 	25,  50 , SBN, SBN, [200, 200, 10]),	
	("spl100-sbn-sbn-200", 			25, 100 , SBN, SBN, [200]),
	("spl100-sbn-sbn-200-200-10", 	25, 100 , SBN, SBN, [200, 200, 10]),	

	("ws-sbn-nade-200-200-10",	    25,   1 , SBN, NADE, [200, 200, 10]),		
	("spl02-sbn-nade-200-200-10",   25,   2 , SBN, NADE, [200, 200, 10]),	
	("spl10-sbn-nade-200-200-10",   25,  10 , SBN, NADE, [200, 200, 10]),	

	("sbn-sbn-200", 			25, 5 , SBN, SBN, [200]),
	("sbn-sbn-500", 			25, 5 , SBN, SBN, [500]),
	("sbn-sbn-200-200", 		25, 5 , SBN, SBN, [200, 200]),	
	("sbn-sbn-200-200-10",		25, 5 , SBN, SBN, [200, 200, 10]),		

	("sbn-darn-200", 			25, 5 , SBN, DARN, [200]),
	("sbn-darn-500", 			25, 5 , SBN, DARN, [500]),
	("sbn-darn-200-200", 		25, 5 , SBN, DARN, [200, 200]),	
	("sbn-darn-200-200-10", 	25, 5 , SBN, DARN, [200, 200, 10]),		

	("sbn-nade-200", 			25, 5 , SBN, NADE, [200]),
	("sbn-nade-500", 			25, 5 , SBN, NADE, [500]),
	("sbn-nade-200-200", 		25, 5 , SBN, NADE, [200, 200]),	
	("sbn-nade-200-200-10", 	25, 5 , SBN, NADE, [200, 200, 10]),		

	("darn-darn-200", 			25, 5 , DARN, DARN, [200]),
	("darn-darn-500", 			25, 5 , DARN, DARN, [500]),
	("darn-darn-200-200", 		25, 5 , DARN, DARN, [200, 200]),	
	("darn-darn-200-200-10", 	25, 5 , DARN, DARN, [200, 200, 10]),		

	("darn-nade-200", 			25, 5 , DARN, NADE, [200]),
	("darn-nade-500", 			25, 5 , DARN, NADE, [500]),
	("darn-nade-200-200", 		25, 5 , DARN, NADE, [200, 200]),	
	("darn-nade-200-200-10", 	25, 5 , DARN, NADE, [200, 200, 10]),			

	("nade-nade-150", 			25, 5 , NADE, NADE, [150]),
	("nade-nade-200", 			25, 5 , NADE, NADE, [200]),
	("nade-nade-250", 			25, 5 , NADE, NADE, [250]),
	("nade-nade-300", 			25, 5 , NADE, NADE, [300]),
	("nade-nade-500", 			25, 5 , NADE, NADE, [500]),
	("nade-nade-200-200", 		25, 5 , NADE, NADE, [200, 200]),	
	("nade-nade-200-200-200", 	25, 5 , NADE, NADE, [200, 200, 200]),		

	("ws-nade-nade-200",        25, 1 , NADE, NADE, [200]),
	("spl02-nade-nade-200",     25, 2 , NADE, NADE, [200]),
	("spl10-nade-nade-200", 	25, 10, NADE, NADE, [200]),
)

_logger = logging.getLogger()


def run_experiment(spec, pickup=None):
    name, batch_size, n_samples, p_layer, q_layer, arch = spec

    _logger.info("Running %s" % name)
    np.random.seed(23)

    if p_layer == SBN:
        p_top = SBNTop
    elif p_layer == DARN:
        p_top = DARNTop
    elif p_layer == NADE:
        p_top = NADETop
    else:
        raise "Unknown Top"
    
    p_layers = []
    q_layers = []

    n_X = 28*28

    for ls in arch:
        n_Y = ls
        p_layers.append(
            p_layer(n_X=n_X, n_Y=n_Y, clamp_sigmoid=True)
        )
        q_layers.append(
            q_layer(n_X=n_Y, n_Y=n_X)
        )
        n_X = n_Y
    p_layers.append( p_top(n_X=n_X, clamp_sigmoid=True) )
            

    model = ISStack(
        p_layers=p_layers,
        q_layers=q_layers
    )
    model.setup()

    preproc = PermuteColumns()
    dataset = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='salakhutdinov_train', preproc=[preproc], n_datapoints=50000)
    valiset = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='salakhutdinov_valid', preproc=[preproc], n_datapoints=1000)
    testset = MNIST(fname="mnist_salakhutdinov.pkl.gz", which_set='test', preproc=[preproc], n_datapoints=10000)

    lr=1e-3
    # Switch to wake-sleep when n_samples=1
    if n_samples == 1:
        lr_p = lr
        lr_q = 0.
        lr_s = lr
    else:
        lr_p = lr
        lr_q = lr
        lr_s = lr
    
    trainer = Trainer(
        batch_size=batch_size,
        n_samples=n_samples,
        learning_rate_p=lr_p,
        learning_rate_q=lr_q,
        learning_rate_s=lr_s,
        layer_discount=1.0,
        anneal=1.,
        dataset=dataset, 
        model=model,
        termination=EarlyStopping(lookahead=5, min_epochs=160),
#        termination=EarlyStopping(max_epochs=1),
        epoch_monitors=[MonitorLL(data=valiset, n_samples=100), DLogModelParams(), SampleFromP(n_samples=100)],
        final_monitors=[MonitorLL(data=testset, n_samples=[1, 5, 10, 25, 100, 500, 1000])],
    )

    tagname = "-".join(TAGS)

    experiment = Experiment()
    experiment.trainer = trainer
    experiment.setup_output_dir("%s-%s" % (tagname, name))
    experiment.print_summary()
    experiment.setup_logging()

    meta = {
        "tag"         : tagname,
        "tags"        : TAGS,
        "name"        : name,
        "batch_size"  : batch_size,
        "n_samples"   : n_samples,
        "p_layer"     : p_layer,
        "q_layer"     : q_layer,
        "arch"        : arch,
        "out_dir"     : experiment.out_dir
    }
   
    with open("run-mnist-grid.%s.state"%tagname, "a") as f:
        pickle.dump(meta, f)

    if pickup is None:
        experiment.run_experiment()
    else:
        experiment.continue_experiment(pickup+"/results.h5")
 
    logger.info("Finished. Wrinting metadata")

    experiment.print_summary()

#=============================================================================
if __name__ == "__main__":
    import argparse 

    logger = logging.getLogger(__name__)

    parser = argparse.ArgumentParser()
    parser.add_argument('--verbose', '-v', action='count')
    parser.add_argument('--random', "-z", action='store_true')
    parser.add_argument('--slurm', action='store_true')
    parser.add_argument('name', nargs='?')
    parser.add_argument('pickup_dir', nargs='?', default=None,
        help="Continue a previous in result_dir")
    args = parser.parse_args()

    FORMAT = '[%(asctime)s] %(module)-15s %(message)s'
    DATEFMT = "%H:%M:%S"
    logging.basicConfig(format=FORMAT, datefmt=DATEFMT, level=logging.INFO)

    if args.random:
        logger.info("Randomly chosing one of %d experiments" % len(SPECS))
        i = np.random.randint(len(SPECS))
        run_experiment(SPECS[i], args.pickup_dir)
    elif args.slurm:
        i = 0
        run_experiment(SPECS[i], args.pickup_dir)
    else:
        for spec in SPECS:
            name, batch_size, n_samples, p_layers, q_layers, arch = spec

            if name == args.name:
                run_experiment(spec, args.pickup_dir)
#        	print "%40s (batch_size=%d, n_samples=%d, arch=%s)" % (name, batch_size, n_samples, arch)


